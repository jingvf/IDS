{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1oP6t2iqvgdNzKOxaA_3_JOAceLHu_eVW",
      "authorship_tag": "ABX9TyNLVzgEHZIRsC9GtKdSCUXW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jingvf/IDS/blob/main/Pytorch_CNNGRU_noDP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "S8Jmwbcv_DdW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 加载数据\n",
        "data_path = '/content/drive/MyDrive/2025paper/dataset/small_dataset.csv'  # 替换为你的数据路径\n",
        "df = pd.read_csv(data_path)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9826b547",
        "outputId": "2f6968ae-4df3-4073-8559-980ff8946f78"
      },
      "source": [
        "!pip install opacus -qq"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/254.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m245.8/254.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.4/254.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 输出类别数量\n",
        "num_classes = df['Class'].nunique()\n",
        "print(f\"总类别数: {num_classes}\")\n",
        "\n",
        "# 输出每个类别的数量\n",
        "class_counts = df['Class'].value_counts()\n",
        "print(\"每个类别的样本数量：\")\n",
        "print(class_counts)\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "EO6bYi9E_3Ut",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c0b79ff-4c4a-446e-e753-f230cfdd7a58"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "总类别数: 5\n",
            "每个类别的样本数量：\n",
            "Class\n",
            "Normal          946844\n",
            "SpoofingRPM      65490\n",
            "SpoofingGear     59725\n",
            "DoS              10553\n",
            "Fuzzy             8967\n",
            "Name: count, dtype: int64\n",
            "      Timestamp CAN ID  DLC Data[0] Data[1] Data[2] Data[3] Data[4] Data[5]  \\\n",
            "0  1.478192e+09    316    8      45      29      24      ff      29      24   \n",
            "1  1.478192e+09    316    8      45      29      24      ff      29      24   \n",
            "2  1.478195e+09   0140    8      00      00      00      00      08      28   \n",
            "3  1.478191e+09   0545    8      d8      00      00      8a      00      00   \n",
            "4  1.478195e+09   043f    8       1      45      60      ff      6b       0   \n",
            "\n",
            "  Data[6] Data[7]         Class  \n",
            "0       0      ff   SpoofingRPM  \n",
            "1       0      ff   SpoofingRPM  \n",
            "2      2f      15        Normal  \n",
            "3      00      00        Normal  \n",
            "4       0       0  SpoofingGear  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# Define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# 1. CAN ID 转成 int（十六进制字符串转十进制数字）\n",
        "df[\"CAN ID\"] = df[\"CAN ID\"].apply(lambda x: int(str(x), 16) if isinstance(x, str) else int(x))\n",
        "\n",
        "# 2. 提取数值特征 (DLC + Data[0-7]) 并转为十进制\n",
        "feature_cols = [\"DLC\"] + [f\"Data[{i}]\" for i in range(8)]\n",
        "# Use .map instead of .applymap for consistency, although applymap was the one triggering the warning\n",
        "X_features = df[feature_cols].astype(str).map(lambda x: int(x, 16) if isinstance(x, str) else int(x)).values\n",
        "\n",
        "# 3. 标准化\n",
        "scaler = StandardScaler()\n",
        "X_features_scaled = scaler.fit_transform(X_features)\n",
        "\n",
        "# 4. CAN ID 单独提取\n",
        "X_canid = df[\"CAN ID\"].values\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(df[\"Class\"].values)\n",
        "# Calculate class weights\n",
        "import numpy as np\n",
        "\n",
        "counts = [946844, 65490, 59725, 10553, 8967] # Using the counts from the previous output\n",
        "total = sum(counts)\n",
        "class_weights = [total/c for c in counts]\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)"
      ],
      "metadata": {
        "id": "A0HmSkdw_2CI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f3e8c44-6560-4342-bd03-64428473e2f7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ===== 第一步：划分训练集 + 临时集（验证+测试） =====\n",
        "X_train_cid, X_temp_cid, X_train_feat, X_temp_feat, y_train, y_temp = train_test_split(\n",
        "    X_canid, X_features_scaled, y_encoded, test_size=0.3, random_state=42\n",
        ")\n",
        "# 这里 test_size=0.3 表示 30% 留作验证+测试\n",
        "\n",
        "# ===== 第二步：从临时集划分验证集和测试集 =====\n",
        "X_val_cid, X_test_cid, X_val_feat, X_test_feat, y_val, y_test = train_test_split(\n",
        "    X_temp_cid, X_temp_feat, y_temp, test_size=0.5, random_state=42\n",
        ")\n",
        "# test_size=0.5 表示临时集一半做测试，一半做验证\n",
        "\n",
        "# ===== 输出检查 =====\n",
        "print(\"原始数据：\")\n",
        "print(f\"X_canid shape = {X_canid.shape}\")\n",
        "print(f\"X_features_scaled shape = {X_features_scaled.shape}\")\n",
        "print(f\"y_encoded shape = {y_encoded.shape}\")\n",
        "\n",
        "print(\"\\n训练集：\")\n",
        "print(f\"CAN IDs shape = {X_train_cid.shape}\")\n",
        "print(f\"Features shape = {X_train_feat.shape}\")\n",
        "print(f\"Labels shape = {y_train.shape}\")\n",
        "\n",
        "print(\"\\n验证集：\")\n",
        "print(f\"CAN IDs shape = {X_val_cid.shape}\")\n",
        "print(f\"Features shape = {X_val_feat.shape}\")\n",
        "print(f\"Labels shape = {y_val.shape}\")\n",
        "\n",
        "print(\"\\n测试集：\")\n",
        "print(f\"CAN IDs shape = {X_test_cid.shape}\")\n",
        "print(f\"Features shape = {X_test_feat.shape}\")\n",
        "print(f\"Labels shape = {y_test.shape}\")\n",
        "\n",
        "print(\"\\n类别映射：\")\n",
        "print(dict(zip(le.classes_, le.transform(le.classes_))))\n"
      ],
      "metadata": {
        "id": "SnhzQDgAAT9Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aae2f6c-db4a-4fc5-d989-7e5127380c4f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "原始数据：\n",
            "X_canid shape = (1091579,)\n",
            "X_features_scaled shape = (1091579, 9)\n",
            "y_encoded shape = (1091579,)\n",
            "\n",
            "训练集：\n",
            "CAN IDs shape = (764105,)\n",
            "Features shape = (764105, 9)\n",
            "Labels shape = (764105,)\n",
            "\n",
            "验证集：\n",
            "CAN IDs shape = (163737,)\n",
            "Features shape = (163737, 9)\n",
            "Labels shape = (163737,)\n",
            "\n",
            "测试集：\n",
            "CAN IDs shape = (163737,)\n",
            "Features shape = (163737, 9)\n",
            "Labels shape = (163737,)\n",
            "\n",
            "类别映射：\n",
            "{'DoS': np.int64(0), 'Fuzzy': np.int64(1), 'Normal': np.int64(2), 'SpoofingGear': np.int64(3), 'SpoofingRPM': np.int64(4)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opacus==1.1.3 -q # 指定稳定版本\n",
        "import opacus\n",
        "print(opacus.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2Ll7Z8fTD8c",
        "outputId": "27351194-9222-40bf-e088-390408e63cc2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/181.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m174.1/181.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.7/181.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h1.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# ======================\n",
        "# 1. 数据集定义\n",
        "# ======================\n",
        "SEQ_LEN = 5\n",
        "class CANSequenceDataset(Dataset):\n",
        "    def __init__(self, canid, features, labels, seq_len=SEQ_LEN):\n",
        "        self.seq_len = seq_len\n",
        "        self.features = torch.tensor(np.array(features, dtype=np.float32))\n",
        "        self.canid = torch.tensor(np.array(canid, dtype=np.int64))\n",
        "        self.labels = torch.tensor(np.array(labels, dtype=np.int64))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels) - self.seq_len + 1\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq_canid = self.canid[idx:idx+self.seq_len].clone().detach()\n",
        "        seq_features = self.features[idx:idx+self.seq_len].clone().detach()\n",
        "        label = self.labels[idx+self.seq_len-1].clone().detach()\n",
        "        return seq_canid, seq_features, label"
      ],
      "metadata": {
        "id": "ABr4dGt-B-hs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "train_dataset = CANSequenceDataset(X_train_cid, X_train_feat, y_train, seq_len=SEQ_LEN)\n",
        "val_dataset   = CANSequenceDataset(X_val_cid, X_val_feat, y_val, seq_len=SEQ_LEN)\n",
        "test_dataset  = CANSequenceDataset(X_test_cid, X_test_feat, y_test, seq_len=SEQ_LEN)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
        "\n",
        "# 打印一个 batch 的 shape\n",
        "for batch in train_loader:\n",
        "    cids, feats, labels = batch\n",
        "    print(\"Batch CAN ID shape:\", cids.shape)       # (BATCH_SIZE, SEQ_LEN)\n",
        "    print(\"Batch Features shape:\", feats.shape)    # (BATCH_SIZE, SEQ_LEN, 9)\n",
        "    print(\"Batch Labels shape:\", labels.shape)     # (BATCH_SIZE,)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFPNkVjONzr5",
        "outputId": "05be11a8-6989-4600-b9a2-bd5f1fb3bd20"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch CAN ID shape: torch.Size([128, 5])\n",
            "Batch Features shape: torch.Size([128, 5, 9])\n",
            "Batch Labels shape: torch.Size([128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cS3agXWQNdtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class CNN_GRU_Model(nn.Module):\n",
        "    def __init__(self, num_features, hidden_dim, num_classes,\n",
        "                 cnn_channels=64, kernel_size=3, num_layers=1):\n",
        "        super(CNN_GRU_Model_V2, self).__init__()\n",
        "\n",
        "        # CNN部分 - 处理每个时间步的特征\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=num_features, out_channels=cnn_channels,\n",
        "                     kernel_size=kernel_size, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(cnn_channels),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Conv1d(in_channels=cnn_channels, out_channels=cnn_channels,\n",
        "                     kernel_size=kernel_size, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(cnn_channels),\n",
        "            nn.Dropout(0.2)\n",
        "        )\n",
        "\n",
        "        # GRU部分\n",
        "        self.gru = nn.GRU(input_size=cnn_channels, hidden_size=hidden_dim,\n",
        "                         batch_first=True, bidirectional=True,  # 使用双向GRU\n",
        "                         num_layers=num_layers)\n",
        "\n",
        "        # 分类层\n",
        "        self.fc = nn.Linear(hidden_dim * 2, num_classes)  # 双向GRU输出维度是2*hidden_dim\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, seq_len, num_features)\n",
        "        # 转换维度用于CNN: (batch, features, seq_len)\n",
        "        x = x.transpose(1, 2)\n",
        "        # CNN特征提取\n",
        "        cnn_out = self.cnn(x)  # (batch, cnn_channels, seq_len)\n",
        "        # 转换回GRU需要的维度: (batch, seq_len, cnn_channels)\n",
        "        gru_input = cnn_out.transpose(1, 2)\n",
        "        # GRU时序建模\n",
        "        gru_out, _ = self.gru(gru_input)  # (batch, seq_len, hidden_dim*2)\n",
        "        # 取最后一个时间步的输出\n",
        "        last_output = gru_out[:, -1, :]  # (batch, hidden_dim*2)\n",
        "        # 分类\n",
        "        output = self.fc(self.dropout(last_output))\n",
        "        return output"
      ],
      "metadata": {
        "id": "pJIo5mhuN3O8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KCNMgOBhNc28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "41wzX1k_Ncw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "EPOCHS=5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss, total_correct = 0, 0\n",
        "\n",
        "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\", leave=False)\n",
        "    for cids, feats, labels in progress_bar:\n",
        "        feats, labels = feats.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(feats)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        total_loss += loss.item() * labels.size(0)\n",
        "        total_correct += (preds == labels).sum().item()\n",
        "\n",
        "        # 实时更新进度条状态\n",
        "        progress_bar.set_postfix({'loss': total_loss/((progress_bar.n+1)*BATCH_SIZE),\n",
        "                                  'acc': total_correct/((progress_bar.n+1)*BATCH_SIZE)})\n",
        "\n",
        "    train_loss = total_loss / len(train_dataset)\n",
        "    train_acc  = total_correct / len(train_dataset)\n",
        "    print(f\"Epoch {epoch+1} → Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
        "\n",
        "    # 验证\n",
        "    model.eval()\n",
        "    val_correct, val_total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for cids, feats, labels in val_loader:\n",
        "            feats, labels = feats.to(device), labels.to(device)\n",
        "            outputs = model(feats)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            val_correct += (preds == labels).sum().item()\n",
        "            val_total += labels.size(0)\n",
        "    val_acc = val_correct / val_total\n",
        "    print(f\"Epoch {epoch+1} → Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "    # 测试集最终评估\n",
        "    # -------------------------------\n",
        "    model.eval()\n",
        "    test_correct, test_total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for cids, feats, labels in test_loader:\n",
        "            feats, labels = feats.to(device), labels.to(device)\n",
        "            outputs = model(feats)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            test_correct += (preds == labels).sum().item()\n",
        "            test_total += labels.size(0)\n",
        "\n",
        "    test_acc = test_correct / test_total\n",
        "    print(f\"\\nFinal Test Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eZ7Ta9aN6m1",
        "outputId": "7fa80e39-bd68-498a-87a3-b042372be460"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 → Train Loss: 0.0102, Train Acc: 0.9877\n",
            "Epoch 1 → Val Acc: 0.9889\n",
            "\n",
            "Final Test Accuracy: 0.9889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 → Train Loss: 0.0086, Train Acc: 0.9883\n",
            "Epoch 2 → Val Acc: 0.9886\n",
            "\n",
            "Final Test Accuracy: 0.9885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 → Train Loss: 0.0081, Train Acc: 0.9885\n",
            "Epoch 3 → Val Acc: 0.9893\n",
            "\n",
            "Final Test Accuracy: 0.9892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 → Train Loss: 0.0077, Train Acc: 0.9886\n",
            "Epoch 4 → Val Acc: 0.9892\n",
            "\n",
            "Final Test Accuracy: 0.9892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 → Train Loss: 0.0074, Train Acc: 0.9887\n",
            "Epoch 5 → Val Acc: 0.9893\n",
            "\n",
            "Final Test Accuracy: 0.9893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5b08ee6"
      },
      "source": [
        "After installing the library, please run the code cell again."
      ]
    }
  ]
}